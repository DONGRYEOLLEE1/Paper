{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-25 16:26:06.925681: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-25 16:26:07.632807: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments, DataCollatorWithPadding\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from datasets import load_dataset, load_metric\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "import evaluate\n",
    "\n",
    "import os\n",
    "# os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "os.environ['MASTER_ADDR'] = 'localhost'\n",
    "os.environ['MASTER_PORT'] = '9994' # modify if RuntimeError: Address already in use\n",
    "os.environ['RANK'] = '0'\n",
    "os.environ['LOCAL_RANK'] = '0'\n",
    "os.environ['WORLD_SIZE'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset yelp_review_full (/home/bigster/.cache/huggingface/datasets/yelp_review_full/yelp_review_full/1.0.0/e8e18e19d7be9e75642fc66b198abadb116f73599ec89a69ba5dd8d1e57ba0bf)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe5b60bb168044988bd8b6bef43b5bc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset(\"yelp_review_full\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 단 1번의 스텝으로 데이터를 처리하기 위해, `Datasets.map` method를 사용하자\n",
    "- `multiprocessing` 이랑 비슷한 mechanism 인듯?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize_fn\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/bigster/.cache/huggingface/datasets/yelp_review_full/yelp_review_full/1.0.0/e8e18e19d7be9e75642fc66b198abadb116f73599ec89a69ba5dd8d1e57ba0bf/cache-64d6404193e8d0b4.arrow\n",
      "Loading cached processed dataset at /home/bigster/.cache/huggingface/datasets/yelp_review_full/yelp_review_full/1.0.0/e8e18e19d7be9e75642fc66b198abadb116f73599ec89a69ba5dd8d1e57ba0bf/cache-32a25b1122eef73f.arrow\n",
      "Loading cached shuffled indices for dataset at /home/bigster/.cache/huggingface/datasets/yelp_review_full/yelp_review_full/1.0.0/e8e18e19d7be9e75642fc66b198abadb116f73599ec89a69ba5dd8d1e57ba0bf/cache-c45c2b5ee50b85dc.arrow\n",
      "Loading cached shuffled indices for dataset at /home/bigster/.cache/huggingface/datasets/yelp_review_full/yelp_review_full/1.0.0/e8e18e19d7be9e75642fc66b198abadb116f73599ec89a69ba5dd8d1e57ba0bf/cache-85ddd7c92ccad2ff.arrow\n"
     ]
    }
   ],
   "source": [
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "small_train_dataset = tokenized_datasets[\"train\"].shuffle(seed=42).select(range(1000))\n",
    "small_eval_dataset = tokenized_datasets[\"test\"].shuffle(seed=42).select(range(1000))\n",
    "\n",
    "# data_collator = DataCollatorWithPadding(tokenizer = tokenizer)\n",
    "# tokenized_datasets.set_format('torch')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train\n",
    "- HF의 `Trainer` API는 logging, gradient_accumulation, max_precision과 같은 다양한 학습 옵션을 지원"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 모델과 레이블 개수를 정확하게 명시해주기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\", num_labels=5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `TrainingArguments` 클래스 안에 모든 H-params를 포함시킬 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(output_dir = './test_trainer')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `Trainer`는 학습 중에 모델 성능에 대해 자동적으로 평가해주지 않음\n",
    "- 그래서 `Trainer`를 성능 평가를 연산해주는 함수에 pass 시켜줘야함\n",
    "- `Evaluate` 라이브러리는 간단한 accuracy 함수를 제공하며 `evaluate.load`를 통해 쉽게 불러올 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `evaluation_strategy` 파라미터에 metrics 함수를 넣어 각 epoch의 끝마다 평가 함수를 report 받을 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "Using cuda_amp half precision backend\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(output_dir=\"./test_trainer\", evaluation_strategy=\"epoch\", \n",
    "                                  deepspeed = 'ds_config_zero2.json', save_total_limit = 1, \n",
    "                                  fp16 = True)\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model = model,\n",
    "    args = training_args,\n",
    "    train_dataset = small_train_dataset,\n",
    "    eval_dataset = small_eval_dataset,\n",
    "    compute_metrics = compute_metrics\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-05-25 16:49:07,047] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.9.2, git-hash=unknown, git-branch=unknown\n",
      "[2023-05-25 16:49:07,048] [WARNING] [config_utils.py:69:_process_deprecated_field] Config parameter cpu_offload is deprecated use offload_optimizer instead\n",
      "[2023-05-25 16:49:07,078] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
      "\u001b[93m [WARNING] \u001b[0m cpu_adam cuda is missing or is incompatible with installed torch, only cpu ops can be compiled!\n",
      "Time to load cpu_adam op: 2.158184289932251 seconds\n",
      "[2023-05-25 16:49:10,335] [INFO] [logging.py:96:log_dist] [Rank 0] Using DeepSpeed Optimizer param name adamw as basic optimizer\n",
      "Adam Optimizer #2 is created with AVX2 arithmetic capability.\n",
      "Config: alpha=0.000050, betas=(0.900000, 0.999000), weight_decay=0.000000, adam_w=1\n",
      "[2023-05-25 16:49:10,341] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = DeepSpeedCPUAdam\n",
      "[2023-05-25 16:49:10,342] [INFO] [utils.py:54:is_zero_supported_optimizer] Checking ZeRO support for optimizer=DeepSpeedCPUAdam type=<class 'deepspeed.ops.adam.cpu_adam.DeepSpeedCPUAdam'>\n",
      "[2023-05-25 16:49:10,342] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.float16 ZeRO stage 2 optimizer\n",
      "[2023-05-25 16:49:10,343] [INFO] [stage_1_and_2.py:133:__init__] Reduce bucket size 200000000\n",
      "[2023-05-25 16:49:10,343] [INFO] [stage_1_and_2.py:134:__init__] Allgather bucket size 200000000\n",
      "[2023-05-25 16:49:10,343] [INFO] [stage_1_and_2.py:135:__init__] CPU Offload: True\n",
      "[2023-05-25 16:49:10,343] [INFO] [stage_1_and_2.py:136:__init__] Round robin gradient partitioning: False\n",
      "Time to load utils op: 0.0008683204650878906 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using /home/bigster/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module cpu_adam, skipping build step...\n",
      "Loading extension module cpu_adam...\n",
      "Using /home/bigster/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module utils, skipping build step...\n",
      "Loading extension module utils...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank: 0 partition count [1] and sizes[(108314118, False)] \n",
      "[2023-05-25 16:49:10,947] [INFO] [utils.py:785:see_memory_usage] Before initializing optimizer states\n",
      "[2023-05-25 16:49:10,948] [INFO] [utils.py:786:see_memory_usage] MA 0.66 GB         Max_MA 0.75 GB         CA 0.76 GB         Max_CA 1 GB \n",
      "[2023-05-25 16:49:10,949] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 10.69 GB, percent = 17.0%\n",
      "[2023-05-25 16:49:11,392] [INFO] [utils.py:785:see_memory_usage] After initializing optimizer states\n",
      "[2023-05-25 16:49:11,393] [INFO] [utils.py:786:see_memory_usage] MA 0.66 GB         Max_MA 0.66 GB         CA 0.76 GB         Max_CA 1 GB \n",
      "[2023-05-25 16:49:11,394] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 11.48 GB, percent = 18.3%\n",
      "[2023-05-25 16:49:11,394] [INFO] [stage_1_and_2.py:489:__init__] optimizer state initialized\n",
      "[2023-05-25 16:49:11,520] [INFO] [utils.py:785:see_memory_usage] After initializing ZeRO optimizer\n",
      "[2023-05-25 16:49:11,520] [INFO] [utils.py:786:see_memory_usage] MA 0.66 GB         Max_MA 0.66 GB         CA 0.76 GB         Max_CA 1 GB \n",
      "[2023-05-25 16:49:11,521] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 11.48 GB, percent = 18.3%\n",
      "[2023-05-25 16:49:11,585] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = adamw\n",
      "[2023-05-25 16:49:11,585] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using configured LR scheduler = WarmupLR\n",
      "[2023-05-25 16:49:11,586] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = <deepspeed.runtime.lr_schedules.WarmupLR object at 0x7f164012d180>\n",
      "[2023-05-25 16:49:11,586] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[5e-05], mom=[[0.9, 0.999]]\n",
      "[2023-05-25 16:49:11,587] [INFO] [config.py:955:print] DeepSpeedEngine configuration:\n",
      "[2023-05-25 16:49:11,587] [INFO] [config.py:959:print]   activation_checkpointing_config  {\n",
      "    \"partition_activations\": false, \n",
      "    \"contiguous_memory_optimization\": false, \n",
      "    \"cpu_checkpointing\": false, \n",
      "    \"number_checkpoints\": null, \n",
      "    \"synchronize_checkpoint_boundary\": false, \n",
      "    \"profile\": false\n",
      "}\n",
      "[2023-05-25 16:49:11,588] [INFO] [config.py:959:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
      "[2023-05-25 16:49:11,588] [INFO] [config.py:959:print]   amp_enabled .................. False\n",
      "[2023-05-25 16:49:11,589] [INFO] [config.py:959:print]   amp_params ................... False\n",
      "[2023-05-25 16:49:11,589] [INFO] [config.py:959:print]   autotuning_config ............ {\n",
      "    \"enabled\": false, \n",
      "    \"start_step\": null, \n",
      "    \"end_step\": null, \n",
      "    \"metric_path\": null, \n",
      "    \"arg_mappings\": null, \n",
      "    \"metric\": \"throughput\", \n",
      "    \"model_info\": null, \n",
      "    \"results_dir\": \"autotuning_results\", \n",
      "    \"exps_dir\": \"autotuning_exps\", \n",
      "    \"overwrite\": true, \n",
      "    \"fast\": true, \n",
      "    \"start_profile_step\": 3, \n",
      "    \"end_profile_step\": 5, \n",
      "    \"tuner_type\": \"gridsearch\", \n",
      "    \"tuner_early_stopping\": 5, \n",
      "    \"tuner_num_trials\": 50, \n",
      "    \"model_info_path\": null, \n",
      "    \"mp_size\": 1, \n",
      "    \"max_train_batch_size\": null, \n",
      "    \"min_train_batch_size\": 1, \n",
      "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
      "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
      "    \"num_tuning_micro_batch_sizes\": 3\n",
      "}\n",
      "[2023-05-25 16:49:11,590] [INFO] [config.py:959:print]   bfloat16_enabled ............. False\n",
      "[2023-05-25 16:49:11,590] [INFO] [config.py:959:print]   checkpoint_parallel_write_pipeline  False\n",
      "[2023-05-25 16:49:11,591] [INFO] [config.py:959:print]   checkpoint_tag_validation_enabled  True\n",
      "[2023-05-25 16:49:11,591] [INFO] [config.py:959:print]   checkpoint_tag_validation_fail  False\n",
      "[2023-05-25 16:49:11,592] [INFO] [config.py:959:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f1564a75240>\n",
      "[2023-05-25 16:49:11,592] [INFO] [config.py:959:print]   communication_data_type ...... None\n",
      "[2023-05-25 16:49:11,593] [INFO] [config.py:959:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
      "[2023-05-25 16:49:11,593] [INFO] [config.py:959:print]   curriculum_enabled_legacy .... False\n",
      "[2023-05-25 16:49:11,594] [INFO] [config.py:959:print]   curriculum_params_legacy ..... False\n",
      "[2023-05-25 16:49:11,594] [INFO] [config.py:959:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\n",
      "[2023-05-25 16:49:11,595] [INFO] [config.py:959:print]   data_efficiency_enabled ...... False\n",
      "[2023-05-25 16:49:11,595] [INFO] [config.py:959:print]   dataloader_drop_last ......... False\n",
      "[2023-05-25 16:49:11,595] [INFO] [config.py:959:print]   disable_allgather ............ False\n",
      "[2023-05-25 16:49:11,596] [INFO] [config.py:959:print]   dump_state ................... False\n",
      "[2023-05-25 16:49:11,596] [INFO] [config.py:959:print]   dynamic_loss_scale_args ...... {'init_scale': 65536, 'scale_window': 1000, 'delayed_shift': 2, 'min_scale': 1}\n",
      "[2023-05-25 16:49:11,596] [INFO] [config.py:959:print]   eigenvalue_enabled ........... False\n",
      "[2023-05-25 16:49:11,597] [INFO] [config.py:959:print]   eigenvalue_gas_boundary_resolution  1\n",
      "[2023-05-25 16:49:11,597] [INFO] [config.py:959:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
      "[2023-05-25 16:49:11,598] [INFO] [config.py:959:print]   eigenvalue_layer_num ......... 0\n",
      "[2023-05-25 16:49:11,598] [INFO] [config.py:959:print]   eigenvalue_max_iter .......... 100\n",
      "[2023-05-25 16:49:11,599] [INFO] [config.py:959:print]   eigenvalue_stability ......... 1e-06\n",
      "[2023-05-25 16:49:11,599] [INFO] [config.py:959:print]   eigenvalue_tol ............... 0.01\n",
      "[2023-05-25 16:49:11,600] [INFO] [config.py:959:print]   eigenvalue_verbose ........... False\n",
      "[2023-05-25 16:49:11,600] [INFO] [config.py:959:print]   elasticity_enabled ........... False\n",
      "[2023-05-25 16:49:11,601] [INFO] [config.py:959:print]   flops_profiler_config ........ {\n",
      "    \"enabled\": false, \n",
      "    \"profile_step\": 1, \n",
      "    \"module_depth\": -1, \n",
      "    \"top_modules\": 1, \n",
      "    \"detailed\": true, \n",
      "    \"output_file\": null\n",
      "}\n",
      "[2023-05-25 16:49:11,605] [INFO] [config.py:959:print]   fp16_auto_cast ............... False\n",
      "[2023-05-25 16:49:11,605] [INFO] [config.py:959:print]   fp16_enabled ................. True\n",
      "[2023-05-25 16:49:11,606] [INFO] [config.py:959:print]   fp16_master_weights_and_gradients  False\n",
      "[2023-05-25 16:49:11,606] [INFO] [config.py:959:print]   global_rank .................. 0\n",
      "[2023-05-25 16:49:11,607] [INFO] [config.py:959:print]   grad_accum_dtype ............. None\n",
      "[2023-05-25 16:49:11,607] [INFO] [config.py:959:print]   gradient_accumulation_steps .. 1\n",
      "[2023-05-25 16:49:11,608] [INFO] [config.py:959:print]   gradient_clipping ............ 1.0\n",
      "[2023-05-25 16:49:11,608] [INFO] [config.py:959:print]   gradient_predivide_factor .... 1.0\n",
      "[2023-05-25 16:49:11,609] [INFO] [config.py:959:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8\n",
      "[2023-05-25 16:49:11,610] [INFO] [config.py:959:print]   initial_dynamic_scale ........ 65536\n",
      "[2023-05-25 16:49:11,610] [INFO] [config.py:959:print]   load_universal_checkpoint .... False\n",
      "[2023-05-25 16:49:11,611] [INFO] [config.py:959:print]   loss_scale ................... 0\n",
      "[2023-05-25 16:49:11,611] [INFO] [config.py:959:print]   memory_breakdown ............. False\n",
      "[2023-05-25 16:49:11,612] [INFO] [config.py:959:print]   mics_hierarchial_params_gather  False\n",
      "[2023-05-25 16:49:11,612] [INFO] [config.py:959:print]   mics_shard_size .............. -1\n",
      "[2023-05-25 16:49:11,613] [INFO] [config.py:959:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False\n",
      "[2023-05-25 16:49:11,613] [INFO] [config.py:959:print]   nebula_config ................ {\n",
      "    \"enabled\": false, \n",
      "    \"persistent_storage_path\": null, \n",
      "    \"persistent_time_interval\": 100, \n",
      "    \"num_of_version_in_retention\": 2, \n",
      "    \"enable_nebula_load\": true, \n",
      "    \"load_path\": null\n",
      "}\n",
      "[2023-05-25 16:49:11,613] [INFO] [config.py:959:print]   optimizer_legacy_fusion ...... False\n",
      "[2023-05-25 16:49:11,614] [INFO] [config.py:959:print]   optimizer_name ............... adamw\n",
      "[2023-05-25 16:49:11,614] [INFO] [config.py:959:print]   optimizer_params ............. {'lr': 5e-05, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0.0}\n",
      "[2023-05-25 16:49:11,615] [INFO] [config.py:959:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}\n",
      "[2023-05-25 16:49:11,616] [INFO] [config.py:959:print]   pld_enabled .................. False\n",
      "[2023-05-25 16:49:11,617] [INFO] [config.py:959:print]   pld_params ................... False\n",
      "[2023-05-25 16:49:11,617] [INFO] [config.py:959:print]   prescale_gradients ........... False\n",
      "[2023-05-25 16:49:11,618] [INFO] [config.py:959:print]   scheduler_name ............... WarmupLR\n",
      "[2023-05-25 16:49:11,618] [INFO] [config.py:959:print]   scheduler_params ............. {'warmup_min_lr': 0, 'warmup_max_lr': 5e-05, 'warmup_num_steps': 0}\n",
      "[2023-05-25 16:49:11,619] [INFO] [config.py:959:print]   sparse_attention ............. None\n",
      "[2023-05-25 16:49:11,620] [INFO] [config.py:959:print]   sparse_gradients_enabled ..... False\n",
      "[2023-05-25 16:49:11,620] [INFO] [config.py:959:print]   steps_per_print .............. 10\n",
      "[2023-05-25 16:49:11,621] [INFO] [config.py:959:print]   train_batch_size ............. 8\n",
      "[2023-05-25 16:49:11,621] [INFO] [config.py:959:print]   train_micro_batch_size_per_gpu  8\n",
      "[2023-05-25 16:49:11,621] [INFO] [config.py:959:print]   use_node_local_storage ....... False\n",
      "[2023-05-25 16:49:11,622] [INFO] [config.py:959:print]   wall_clock_breakdown ......... False\n",
      "[2023-05-25 16:49:11,622] [INFO] [config.py:959:print]   world_size ................... 1\n",
      "[2023-05-25 16:49:11,623] [INFO] [config.py:959:print]   zero_allow_untested_optimizer  False\n",
      "[2023-05-25 16:49:11,623] [INFO] [config.py:959:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=200000000 allgather_partitions=True allgather_bucket_size=200000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=DeepSpeedZeroOffloadOptimizerConfig(device='cpu', nvme_path=None, buffer_count=4, pin_memory=False, pipeline=False, pipeline_read=False, pipeline_write=False, fast_init=False) sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True\n",
      "[2023-05-25 16:49:11,624] [INFO] [config.py:959:print]   zero_enabled ................. True\n",
      "[2023-05-25 16:49:11,624] [INFO] [config.py:959:print]   zero_force_ds_cpu_optimizer .. True\n",
      "[2023-05-25 16:49:11,625] [INFO] [config.py:959:print]   zero_optimization_stage ...... 2\n",
      "[2023-05-25 16:49:11,625] [INFO] [config.py:945:print_user_config]   json = {\n",
      "    \"fp16\": {\n",
      "        \"enabled\": true, \n",
      "        \"loss_scale\": 0, \n",
      "        \"loss_scale_window\": 1000, \n",
      "        \"initial_scale_power\": 16, \n",
      "        \"hysteresis\": 2, \n",
      "        \"min_loss_scale\": 1\n",
      "    }, \n",
      "    \"optimizer\": {\n",
      "        \"type\": \"AdamW\", \n",
      "        \"params\": {\n",
      "            \"lr\": 5e-05, \n",
      "            \"betas\": [0.9, 0.999], \n",
      "            \"eps\": 1e-08, \n",
      "            \"weight_decay\": 0.0\n",
      "        }\n",
      "    }, \n",
      "    \"scheduler\": {\n",
      "        \"type\": \"WarmupLR\", \n",
      "        \"params\": {\n",
      "            \"warmup_min_lr\": 0, \n",
      "            \"warmup_max_lr\": 5e-05, \n",
      "            \"warmup_num_steps\": 0\n",
      "        }\n",
      "    }, \n",
      "    \"zero_optimization\": {\n",
      "        \"stage\": 2, \n",
      "        \"allgather_partitions\": true, \n",
      "        \"allgather_bucket_size\": 2.000000e+08, \n",
      "        \"overlap_comm\": true, \n",
      "        \"reduce_scatter\": true, \n",
      "        \"reduce_bucket_size\": 2.000000e+08, \n",
      "        \"contiguous_gradients\": true, \n",
      "        \"cpu_offload\": true\n",
      "    }, \n",
      "    \"gradient_accumulation_steps\": 1, \n",
      "    \"gradient_clipping\": 1.0, \n",
      "    \"train_batch_size\": 8, \n",
      "    \"train_micro_batch_size_per_gpu\": 8\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using /home/bigster/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module utils, skipping build step...\n",
      "Loading extension module utils...\n",
      "***** Running training *****\n",
      "  Num examples = 1000\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 375\n",
      "  Number of trainable parameters = 108314117\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to load utils op: 0.0018157958984375 seconds\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e5a723f402440be8fd35ad71133610f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-05-25 16:49:11,796] [INFO] [loss_scaler.py:188:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 65536, but hysteresis is 2. Reducing hysteresis to 1\n",
      "[2023-05-25 16:49:11,931] [INFO] [loss_scaler.py:181:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 65536, reducing to 32768\n",
      "[2023-05-25 16:49:13,200] [INFO] [loss_scaler.py:181:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 32768, reducing to 16384\n",
      "[2023-05-25 16:49:14,663] [INFO] [logging.py:96:log_dist] [Rank 0] step=10, skipped=3, lr=[5e-05], mom=[[0.9, 0.999]]\n",
      "[2023-05-25 16:49:14,664] [INFO] [timer.py:199:stop] epoch=0/micro_step=10/global_step=10, RunningAvgSamplesPerSec=23.975885802684157, CurrSamplesPerSec=22.51934495146732, MemAllocated=0.26GB, MaxMemAllocated=3.67GB\n",
      "[2023-05-25 16:49:18,359] [INFO] [logging.py:96:log_dist] [Rank 0] step=20, skipped=3, lr=[5e-05], mom=[[0.9, 0.999]]\n",
      "[2023-05-25 16:49:18,360] [INFO] [timer.py:199:stop] epoch=0/micro_step=20/global_step=20, RunningAvgSamplesPerSec=22.93180123522259, CurrSamplesPerSec=22.532289441575212, MemAllocated=0.26GB, MaxMemAllocated=3.67GB\n",
      "[2023-05-25 16:49:22,083] [INFO] [logging.py:96:log_dist] [Rank 0] step=30, skipped=3, lr=[5e-05], mom=[[0.9, 0.999]]\n",
      "[2023-05-25 16:49:22,083] [INFO] [timer.py:199:stop] epoch=0/micro_step=30/global_step=30, RunningAvgSamplesPerSec=22.593602473511574, CurrSamplesPerSec=22.48552672844288, MemAllocated=0.26GB, MaxMemAllocated=3.67GB\n",
      "[2023-05-25 16:49:25,827] [INFO] [logging.py:96:log_dist] [Rank 0] step=40, skipped=3, lr=[5e-05], mom=[[0.9, 0.999]]\n",
      "[2023-05-25 16:49:25,828] [INFO] [timer.py:199:stop] epoch=0/micro_step=40/global_step=40, RunningAvgSamplesPerSec=22.408044052659207, CurrSamplesPerSec=22.49432989828945, MemAllocated=0.26GB, MaxMemAllocated=3.67GB\n",
      "[2023-05-25 16:49:25,967] [INFO] [loss_scaler.py:181:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 16384, reducing to 8192\n",
      "[2023-05-25 16:49:29,288] [INFO] [logging.py:96:log_dist] [Rank 0] step=50, skipped=4, lr=[5e-05], mom=[[0.9, 0.999]]\n",
      "[2023-05-25 16:49:29,289] [INFO] [timer.py:199:stop] epoch=0/micro_step=50/global_step=50, RunningAvgSamplesPerSec=22.670549578703554, CurrSamplesPerSec=22.513014225272165, MemAllocated=0.26GB, MaxMemAllocated=3.67GB\n",
      "[2023-05-25 16:49:33,007] [INFO] [logging.py:96:log_dist] [Rank 0] step=60, skipped=4, lr=[5e-05], mom=[[0.9, 0.999]]\n",
      "[2023-05-25 16:49:33,008] [INFO] [timer.py:199:stop] epoch=0/micro_step=60/global_step=60, RunningAvgSamplesPerSec=22.552844530722393, CurrSamplesPerSec=22.307428223446365, MemAllocated=0.26GB, MaxMemAllocated=3.67GB\n",
      "[2023-05-25 16:49:36,857] [INFO] [logging.py:96:log_dist] [Rank 0] step=70, skipped=4, lr=[5e-05], mom=[[0.9, 0.999]]\n",
      "[2023-05-25 16:49:36,858] [INFO] [timer.py:199:stop] epoch=0/micro_step=70/global_step=70, RunningAvgSamplesPerSec=22.350608853649064, CurrSamplesPerSec=22.424216826567083, MemAllocated=0.26GB, MaxMemAllocated=3.67GB\n",
      "[2023-05-25 16:49:40,529] [INFO] [logging.py:96:log_dist] [Rank 0] step=80, skipped=4, lr=[5e-05], mom=[[0.9, 0.999]]\n",
      "[2023-05-25 16:49:40,530] [INFO] [timer.py:199:stop] epoch=0/micro_step=80/global_step=80, RunningAvgSamplesPerSec=22.339694162532933, CurrSamplesPerSec=22.238326255123088, MemAllocated=0.26GB, MaxMemAllocated=3.67GB\n",
      "[2023-05-25 16:49:44,162] [INFO] [logging.py:96:log_dist] [Rank 0] step=90, skipped=4, lr=[5e-05], mom=[[0.9, 0.999]]\n",
      "[2023-05-25 16:49:44,163] [INFO] [timer.py:199:stop] epoch=0/micro_step=90/global_step=90, RunningAvgSamplesPerSec=22.358808308742386, CurrSamplesPerSec=22.567842214113966, MemAllocated=0.26GB, MaxMemAllocated=3.67GB\n",
      "[2023-05-25 16:49:47,919] [INFO] [logging.py:96:log_dist] [Rank 0] step=100, skipped=4, lr=[5e-05], mom=[[0.9, 0.999]]\n",
      "[2023-05-25 16:49:47,920] [INFO] [timer.py:199:stop] epoch=0/micro_step=100/global_step=100, RunningAvgSamplesPerSec=22.307714088169206, CurrSamplesPerSec=21.663436626192702, MemAllocated=0.26GB, MaxMemAllocated=3.67GB\n",
      "[2023-05-25 16:49:52,029] [INFO] [logging.py:96:log_dist] [Rank 0] step=110, skipped=4, lr=[5e-05], mom=[[0.9, 0.999]]\n",
      "[2023-05-25 16:49:52,030] [INFO] [timer.py:199:stop] epoch=0/micro_step=110/global_step=110, RunningAvgSamplesPerSec=22.066090678168045, CurrSamplesPerSec=22.25428479334436, MemAllocated=0.26GB, MaxMemAllocated=3.67GB\n",
      "[2023-05-25 16:49:55,757] [INFO] [logging.py:96:log_dist] [Rank 0] step=120, skipped=4, lr=[5e-05], mom=[[0.9, 0.999]]\n",
      "[2023-05-25 16:49:55,758] [INFO] [timer.py:199:stop] epoch=0/micro_step=120/global_step=120, RunningAvgSamplesPerSec=22.05898324176611, CurrSamplesPerSec=22.27031059495357, MemAllocated=0.26GB, MaxMemAllocated=3.67GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1000\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cb858b40fb04e03aaa38f69c681f445",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.3935546875, 'eval_accuracy': 0.537, 'eval_runtime': 3.6843, 'eval_samples_per_second': 271.419, 'eval_steps_per_second': 33.927, 'epoch': 1.0}\n",
      "[2023-05-25 16:50:03,204] [INFO] [logging.py:96:log_dist] [Rank 0] step=130, skipped=4, lr=[5e-05], mom=[[0.9, 0.999]]\n",
      "[2023-05-25 16:50:03,205] [INFO] [timer.py:199:stop] epoch=0/micro_step=130/global_step=130, RunningAvgSamplesPerSec=22.041497142142894, CurrSamplesPerSec=22.20348009295776, MemAllocated=0.26GB, MaxMemAllocated=3.67GB\n",
      "[2023-05-25 16:50:07,104] [INFO] [logging.py:96:log_dist] [Rank 0] step=140, skipped=4, lr=[5e-05], mom=[[0.9, 0.999]]\n",
      "[2023-05-25 16:50:07,105] [INFO] [timer.py:199:stop] epoch=0/micro_step=140/global_step=140, RunningAvgSamplesPerSec=21.96298108863297, CurrSamplesPerSec=21.316013421914924, MemAllocated=0.26GB, MaxMemAllocated=3.67GB\n",
      "[2023-05-25 16:50:11,698] [INFO] [logging.py:96:log_dist] [Rank 0] step=150, skipped=4, lr=[5e-05], mom=[[0.9, 0.999]]\n",
      "[2023-05-25 16:50:11,699] [INFO] [timer.py:199:stop] epoch=0/micro_step=150/global_step=150, RunningAvgSamplesPerSec=21.62014225397057, CurrSamplesPerSec=16.40214006212926, MemAllocated=0.26GB, MaxMemAllocated=3.67GB\n",
      "[2023-05-25 16:50:16,302] [INFO] [logging.py:96:log_dist] [Rank 0] step=160, skipped=4, lr=[5e-05], mom=[[0.9, 0.999]]\n",
      "[2023-05-25 16:50:16,303] [INFO] [timer.py:199:stop] epoch=0/micro_step=160/global_step=160, RunningAvgSamplesPerSec=21.32658812033473, CurrSamplesPerSec=18.983872911413318, MemAllocated=0.26GB, MaxMemAllocated=3.67GB\n",
      "[2023-05-25 16:50:20,023] [INFO] [logging.py:96:log_dist] [Rank 0] step=170, skipped=4, lr=[5e-05], mom=[[0.9, 0.999]]\n",
      "[2023-05-25 16:50:20,024] [INFO] [timer.py:199:stop] epoch=0/micro_step=170/global_step=170, RunningAvgSamplesPerSec=21.366725569646476, CurrSamplesPerSec=20.965191132926748, MemAllocated=0.26GB, MaxMemAllocated=3.67GB\n",
      "[2023-05-25 16:50:24,283] [INFO] [logging.py:96:log_dist] [Rank 0] step=180, skipped=4, lr=[5e-05], mom=[[0.9, 0.999]]\n",
      "[2023-05-25 16:50:24,283] [INFO] [timer.py:199:stop] epoch=0/micro_step=180/global_step=180, RunningAvgSamplesPerSec=21.23059309590436, CurrSamplesPerSec=21.514216101151547, MemAllocated=0.26GB, MaxMemAllocated=3.67GB\n",
      "[2023-05-25 16:50:28,040] [INFO] [logging.py:96:log_dist] [Rank 0] step=190, skipped=4, lr=[5e-05], mom=[[0.9, 0.999]]\n",
      "[2023-05-25 16:50:28,041] [INFO] [timer.py:199:stop] epoch=0/micro_step=190/global_step=190, RunningAvgSamplesPerSec=21.259262707227517, CurrSamplesPerSec=22.21276956319112, MemAllocated=0.26GB, MaxMemAllocated=3.67GB\n",
      "[2023-05-25 16:50:31,843] [INFO] [logging.py:96:log_dist] [Rank 0] step=200, skipped=4, lr=[5e-05], mom=[[0.9, 0.999]]\n",
      "[2023-05-25 16:50:31,844] [INFO] [timer.py:199:stop] epoch=0/micro_step=200/global_step=200, RunningAvgSamplesPerSec=21.273640615596012, CurrSamplesPerSec=22.27921228986108, MemAllocated=0.26GB, MaxMemAllocated=3.67GB\n",
      "[2023-05-25 16:50:35,751] [INFO] [logging.py:96:log_dist] [Rank 0] step=210, skipped=4, lr=[5e-05], mom=[[0.9, 0.999]]\n",
      "[2023-05-25 16:50:35,752] [INFO] [timer.py:199:stop] epoch=0/micro_step=210/global_step=210, RunningAvgSamplesPerSec=21.25719148732326, CurrSamplesPerSec=21.851977131067844, MemAllocated=0.26GB, MaxMemAllocated=3.67GB\n",
      "[2023-05-25 16:50:40,045] [INFO] [logging.py:96:log_dist] [Rank 0] step=220, skipped=4, lr=[5e-05], mom=[[0.9, 0.999]]\n",
      "[2023-05-25 16:50:40,046] [INFO] [timer.py:199:stop] epoch=0/micro_step=220/global_step=220, RunningAvgSamplesPerSec=21.141732097237412, CurrSamplesPerSec=19.077310039536837, MemAllocated=0.26GB, MaxMemAllocated=3.67GB\n",
      "[2023-05-25 16:50:44,147] [INFO] [logging.py:96:log_dist] [Rank 0] step=230, skipped=4, lr=[5e-05], mom=[[0.9, 0.999]]\n",
      "[2023-05-25 16:50:44,148] [INFO] [timer.py:199:stop] epoch=0/micro_step=230/global_step=230, RunningAvgSamplesPerSec=21.086017711993545, CurrSamplesPerSec=21.96764276099743, MemAllocated=0.26GB, MaxMemAllocated=3.67GB\n",
      "[2023-05-25 16:50:47,860] [INFO] [logging.py:96:log_dist] [Rank 0] step=240, skipped=4, lr=[5e-05], mom=[[0.9, 0.999]]\n",
      "[2023-05-25 16:50:47,861] [INFO] [timer.py:199:stop] epoch=0/micro_step=240/global_step=240, RunningAvgSamplesPerSec=21.12567093629667, CurrSamplesPerSec=22.01347269640247, MemAllocated=0.26GB, MaxMemAllocated=3.67GB\n",
      "[2023-05-25 16:50:51,576] [INFO] [logging.py:96:log_dist] [Rank 0] step=250, skipped=4, lr=[5e-05], mom=[[0.9, 0.999]]\n",
      "[2023-05-25 16:50:51,577] [INFO] [timer.py:199:stop] epoch=0/micro_step=250/global_step=250, RunningAvgSamplesPerSec=21.159283363896122, CurrSamplesPerSec=22.86834954579438, MemAllocated=0.26GB, MaxMemAllocated=3.67GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1000\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1aea80f3a524e8bacc10ec1f78f7848",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.9208984375, 'eval_accuracy': 0.528, 'eval_runtime': 3.6897, 'eval_samples_per_second': 271.027, 'eval_steps_per_second': 33.878, 'epoch': 2.0}\n",
      "[2023-05-25 16:50:59,052] [INFO] [logging.py:96:log_dist] [Rank 0] step=260, skipped=4, lr=[5e-05], mom=[[0.9, 0.999]]\n",
      "[2023-05-25 16:50:59,053] [INFO] [timer.py:199:stop] epoch=0/micro_step=260/global_step=260, RunningAvgSamplesPerSec=21.177279172926134, CurrSamplesPerSec=22.67217393713306, MemAllocated=0.26GB, MaxMemAllocated=3.67GB\n",
      "[2023-05-25 16:51:01,862] [INFO] [loss_scaler.py:181:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 8192, reducing to 4096\n",
      "[2023-05-25 16:51:02,592] [INFO] [logging.py:96:log_dist] [Rank 0] step=270, skipped=5, lr=[5e-05], mom=[[0.9, 0.999]]\n",
      "[2023-05-25 16:51:02,593] [INFO] [timer.py:199:stop] epoch=0/micro_step=270/global_step=270, RunningAvgSamplesPerSec=21.24611443487586, CurrSamplesPerSec=22.741289813180074, MemAllocated=0.26GB, MaxMemAllocated=3.67GB\n",
      "[2023-05-25 16:51:06,295] [INFO] [logging.py:96:log_dist] [Rank 0] step=280, skipped=5, lr=[5e-05], mom=[[0.9, 0.999]]\n",
      "[2023-05-25 16:51:06,296] [INFO] [timer.py:199:stop] epoch=0/micro_step=280/global_step=280, RunningAvgSamplesPerSec=21.277581991794666, CurrSamplesPerSec=21.79472020379756, MemAllocated=0.26GB, MaxMemAllocated=3.67GB\n",
      "[2023-05-25 16:51:10,090] [INFO] [logging.py:96:log_dist] [Rank 0] step=290, skipped=5, lr=[5e-05], mom=[[0.9, 0.999]]\n",
      "[2023-05-25 16:51:10,091] [INFO] [timer.py:199:stop] epoch=0/micro_step=290/global_step=290, RunningAvgSamplesPerSec=21.287517068169826, CurrSamplesPerSec=22.207124401711212, MemAllocated=0.26GB, MaxMemAllocated=3.67GB\n",
      "[2023-05-25 16:51:14,029] [INFO] [logging.py:96:log_dist] [Rank 0] step=300, skipped=5, lr=[5e-05], mom=[[0.9, 0.999]]\n",
      "[2023-05-25 16:51:14,029] [INFO] [timer.py:199:stop] epoch=0/micro_step=300/global_step=300, RunningAvgSamplesPerSec=21.269897675523143, CurrSamplesPerSec=22.330632049774426, MemAllocated=0.26GB, MaxMemAllocated=3.67GB\n",
      "[2023-05-25 16:51:17,970] [INFO] [logging.py:96:log_dist] [Rank 0] step=310, skipped=5, lr=[5e-05], mom=[[0.9, 0.999]]\n",
      "[2023-05-25 16:51:17,972] [INFO] [timer.py:199:stop] epoch=0/micro_step=310/global_step=310, RunningAvgSamplesPerSec=21.25096658831246, CurrSamplesPerSec=20.58018773030819, MemAllocated=0.26GB, MaxMemAllocated=3.67GB\n",
      "[2023-05-25 16:51:21,804] [INFO] [logging.py:96:log_dist] [Rank 0] step=320, skipped=5, lr=[5e-05], mom=[[0.9, 0.999]]\n",
      "[2023-05-25 16:51:21,805] [INFO] [timer.py:199:stop] epoch=0/micro_step=320/global_step=320, RunningAvgSamplesPerSec=21.256109815911607, CurrSamplesPerSec=22.389129728369987, MemAllocated=0.26GB, MaxMemAllocated=3.67GB\n",
      "[2023-05-25 16:51:25,522] [INFO] [logging.py:96:log_dist] [Rank 0] step=330, skipped=5, lr=[5e-05], mom=[[0.9, 0.999]]\n",
      "[2023-05-25 16:51:25,523] [INFO] [timer.py:199:stop] epoch=0/micro_step=330/global_step=330, RunningAvgSamplesPerSec=21.280030773893525, CurrSamplesPerSec=22.458211491597186, MemAllocated=0.26GB, MaxMemAllocated=3.67GB\n",
      "[2023-05-25 16:51:29,162] [INFO] [logging.py:96:log_dist] [Rank 0] step=340, skipped=5, lr=[5e-05], mom=[[0.9, 0.999]]\n",
      "[2023-05-25 16:51:29,163] [INFO] [timer.py:199:stop] epoch=0/micro_step=340/global_step=340, RunningAvgSamplesPerSec=21.314452835080946, CurrSamplesPerSec=22.48026921842643, MemAllocated=0.26GB, MaxMemAllocated=3.67GB\n",
      "[2023-05-25 16:51:32,799] [INFO] [logging.py:96:log_dist] [Rank 0] step=350, skipped=5, lr=[5e-05], mom=[[0.9, 0.999]]\n",
      "[2023-05-25 16:51:32,800] [INFO] [timer.py:199:stop] epoch=0/micro_step=350/global_step=350, RunningAvgSamplesPerSec=21.346670598626904, CurrSamplesPerSec=22.62188551938854, MemAllocated=0.26GB, MaxMemAllocated=3.67GB\n",
      "[2023-05-25 16:51:36,447] [INFO] [logging.py:96:log_dist] [Rank 0] step=360, skipped=5, lr=[5e-05], mom=[[0.9, 0.999]]\n",
      "[2023-05-25 16:51:36,448] [INFO] [timer.py:199:stop] epoch=0/micro_step=360/global_step=360, RunningAvgSamplesPerSec=21.375064804108206, CurrSamplesPerSec=22.502294863850597, MemAllocated=0.26GB, MaxMemAllocated=3.67GB\n",
      "[2023-05-25 16:51:40,211] [INFO] [logging.py:96:log_dist] [Rank 0] step=370, skipped=5, lr=[5e-05], mom=[[0.9, 0.999]]\n",
      "[2023-05-25 16:51:40,211] [INFO] [timer.py:199:stop] epoch=0/micro_step=370/global_step=370, RunningAvgSamplesPerSec=21.385777214633475, CurrSamplesPerSec=22.575601117933356, MemAllocated=0.26GB, MaxMemAllocated=3.67GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1000\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b6c7f33493f4e0db1510ee7d24e277b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.4375, 'eval_accuracy': 0.497, 'eval_runtime': 3.6813, 'eval_samples_per_second': 271.64, 'eval_steps_per_second': 33.955, 'epoch': 3.0}\n",
      "{'train_runtime': 154.2573, 'train_samples_per_second': 19.448, 'train_steps_per_second': 2.431, 'train_loss': 0.40657767740885414, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=375, training_loss=0.40657767740885414, metrics={'train_runtime': 154.2573, 'train_samples_per_second': 19.448, 'train_steps_per_second': 2.431, 'train_loss': 0.40657767740885414, 'epoch': 3.0})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./test_trainer\n",
      "Configuration saved in ./test_trainer/config.json\n",
      "Model weights saved in ./test_trainer/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "trainer.save_model('./test_trainer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model\n",
    "del trainer\n",
    "torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
