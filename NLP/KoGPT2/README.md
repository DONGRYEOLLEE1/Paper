# KoGPT2 Sentence Generation

- Base code referred to [ğŸ“˜ THIS BOOK](http://www.yes24.com/Product/Goods/105294979). 

- `KoGPT2_Basemodel_Flask.py`

  -  Used to Base model of [KoGPT2](https://github.com/SKT-AI/KoGPT2)

```python

opyrator launch-ui main:generate_text

```


## Fine tuning
- Fine-tune dataset from [ğŸ¿ NSMC](https://github.com/e9t/nsmc)
<<<<<<< HEAD
> Hyperparameter : `1 epoch`
> Duration : about `80m`
=======
  - Hyperparameter : `1 epoch` 
  - Duration : about `80m`
>>>>>>> 4154ecc83148e0c1859531afb428080140ce3688

- Fine-tun dataset from [ğŸ“° AIHub ë‰´ìŠ¤ê¸°ì‚¬ ê¸°ê³„ë…í•´](https://aihub.or.kr/aihubdata/data/view.do?currMenu=115&topMenu=100&aihubDataSe=realm&dataSetSn=577)
  - `50k data sampling`
  - Hyperparameter : `5 epochs`, `lr.find()`
  - Duration : `3h 40m`


## Result

- Fine-tuned NSMC 

![FTmodel3](https://user-images.githubusercontent.com/82855597/227821512-26ab055c-2265-40d3-a87f-e6cfc0322029.png)

<br> </br>

- Fine-tuned ë‰´ìŠ¤ê¸°ì‚¬ ê¸°ê³„ë…í•´

![metrics1](https://user-images.githubusercontent.com/82855597/227821660-1d5c217c-e181-4fc6-9fb5-68ef8a7f9eee.png)

![metrics2](https://user-images.githubusercontent.com/82855597/227821670-9cb96028-686b-4c84-931e-66567e83db42.png)

![news_res1](https://user-images.githubusercontent.com/82855597/227821679-5b9ecabb-e1de-4106-ae0e-78ce4b211486.png)
 
![news_res2](https://user-images.githubusercontent.com/82855597/227821681-ae0150e8-7e69-4e16-88fc-4d9f8fdaab94.png)


## Save


```python
> def inference_fn(PROMPT,
                 MAX_LENGTH: int,
                 REPETITION_PENALTY: float,
                 TOP_P: float,
                 TOP_K: int):
    prompt = PROMPT,
    encode = tokenizer.encode(PROMPT)
    inp = tensor(encode)[None].cuda()
    output = model.generate(inp,
                                  pad_token_id = tokenizer.pad_token_id,
                                  eos_token_id = tokenizer.eos_token_id,
                                  bos_token_id = tokenizer.bos_token_id,
                                  max_length = MAX_LENGTH,
                                  repetition_penalty = REPETITION_PENALTY,
                                  top_p = TOP_P,
                                  top_k = TOP_K,
                                  use_cache = True
                                  )
    
    return tokenizer.decode(output[0].cpu().numpy())
> inference_fn(""" ì´ë²ˆ ì£¼ì‹ì‹œì¥ì€ """, 200, 1.2, 0.85, 30)

ì´ë²ˆ ì£¼ì‹ì‹œì¥ì€ ë ë¦¬ë¥¼ ì´ì–´ê°€ê¸° ë³´ë‹¤ëŠ” ìˆ˜ê¸‰ì— ì˜í•´ ì¢Œìš°ë  ê²ƒ"ì´ë¼ë©° "ì½”ìŠ¤í”¼ëŠ” ì§€ë‚œí•´ 11ì›” ì‚¬ìƒ ìµœê³ ì¹˜ë¥¼ ê¸°ë¡í•œ ì´í›„ ì¡°ì •ì„ ë°›ê³  ìˆìœ¼ë©° ì™¸êµ­ì¸ 
íˆ¬ììë“¤ì˜ ë§¤ë„ì„¸ê°€ ì´ì–´ì§€ê³  ìˆì–´ ë‹¹ë¶„ê°„ ë°•ìŠ¤ê¶Œ ì¥ì„¸ë¥¼ ë³´ì¼ ê²ƒìœ¼ë¡œ ì˜ˆìƒëœë‹¤"ê³  ë§í–ˆë‹¤ í•œí¸ ì½”ìŠ¤í”¼200 ë³€ë™ì„±ì§€ìˆ˜ëŠ” 033P í•˜ë½í•œ 911ë¡œ ë§ˆê°ëìœ¼ë©° 
ê±°ë˜ëŸ‰ì€ 11ì–µ8ì²œë§Œì£¼ë¡œ ì§‘ê³„ëë‹¤ ì¶©ë¶ ìŒì„±êµ° ëŒ€ì†Œë©´ ì†Œì¬ (ì£¼)ëŒ€ì†Œì „ì£¼ëŒ€í‘œ ê¹€ë¯¼ìˆ˜ì—ì„œ ì§€ì—­ ë‚´ ì–´ë ¤ìš´ ì´ì›ƒì„ ìœ„í•´ ì¨ë‹¬ë¼ë©° ì„±ê¸ˆ 100ë§Œì›” ê¸°íƒí–ˆë‹¤ê³  ë°í˜”ë‹¤ 
(ì£¼)ëŒ€ì†Œì „ì€ ì§€ë‚œ 2019ë…„ë¶€í„° ë§¤ë…„ ëª…ì ˆë§ˆë‹¤ ì§€ì—­ì˜ ì†Œì™¸ê³„ì¸µì„ ìœ„í•œ ë‚˜ëˆ”ê³¼ ë´‰ì‚¬ë¥¼ ì‹¤ì²œí•˜ê³  ìˆë‹¤ íŠ¹íˆ ì˜¬í•´ëŠ” ì½”ë¡œë‚˜19 ì¥ê¸°í™”ë¡œ ì¸í•´ ì–´ë ¤ì›€ì„ ê²ªê³  ìˆëŠ” 
ëŒ€ì†Œë©´ì˜ ì €ì†Œë“ ê°€êµ¬ë¥¼ ì„ ì •í•´ ê°€êµ­ë‹¹ 50ë§Œì›ì”© ëª¨ë‘ 200ë§Œì›ì˜ ì„±ê¸ˆì„ ì „ë‹¬í–ˆë‹¤ ê¹€ë¯¼ìˆ˜ ëŒ€í‘œëŠ” "ì‘ì€ ì •ì„±ì´ì§€ë§Œ ë„ì›€ì´ í•„ìš”í•œ ë¶„ë“¤ì—ê²Œ ì¡°ê¸ˆì´ë‚˜ë§ˆ í˜ì´ ë˜ê¸¸ ë°”ë€ë‹¤"ë©°'
<<<<<<< HEAD
=======

>>>>>>> 4154ecc83148e0c1859531afb428080140ce3688
```


## Reference

https://github.com/SKT-AI/KoGPT2

https://github.com/shbictai/narrativeKoGPT2

https://gyong0117.tistory.com/50

https://github.com/piegu/fastai-projects/blob/master/finetuning-English-GPT2-any-language-Portuguese-HuggingFace-fastaiv2.ipynb

https://github.com/ttop32/KoGPT2novel/blob/main/train.ipynb

https://github.com/haven-jeon/KoGPT2-chatbot
