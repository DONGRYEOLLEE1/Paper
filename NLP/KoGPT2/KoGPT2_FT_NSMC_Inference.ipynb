{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8oaGGhdmYKqt"
      },
      "source": [
        "# 패키지 설치\n",
        "pip 명령어로 의존성 있는 패키지를 설치합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t8TJkXkpDnSq"
      },
      "source": [
        "!pip install ratsnlp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ppGzJeg_x12T"
      },
      "source": [
        "# 구글 드라이브 연동하기\n",
        "모델 체크포인트 등을 저장해 둘 구글 드라이브를 연결합니다. 자신의 구글 계정에 적용됩니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zgSyL_BsVTfl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7c153a2-3aee-488a-b001-e58646cf23e6"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive', force_remount=True)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eC5OwyKMx_l9"
      },
      "source": [
        "# 각종 설정\n",
        "모델 하이퍼파라메터(hyperparameter)와 저장 위치 등 설정 정보를 선언합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKybDwDqFIX5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87469665-afad-45ce-8039-36686ac3cb52"
      },
      "source": [
        "from ratsnlp.nlpbook.generation import GenerationDeployArguments\n",
        "args = GenerationDeployArguments(\n",
        "    pretrained_model_name=\"skt/kogpt2-base-v2\",\n",
        "    downstream_model_dir=\"/gdrive/My Drive/nlpbook/checkpoint-generation\",\n",
        ")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "downstream_model_checkpoint_fpath: /gdrive/My Drive/nlpbook/checkpoint-generation/epoch=1-val_loss=2.29.ckpt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J3mThtbxyNyO"
      },
      "source": [
        "# 모델 로딩\n",
        "파인튜닝을 마친 GPT2 모델과 토크나이저를 읽어 들입니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFV031RZFRgD"
      },
      "source": [
        "import torch\n",
        "from transformers import GPT2Config, GPT2LMHeadModel\n",
        "pretrained_model_config = GPT2Config.from_pretrained(\n",
        "    args.pretrained_model_name,\n",
        ")\n",
        "model = GPT2LMHeadModel(pretrained_model_config)\n",
        "fine_tuned_model_ckpt = torch.load(\n",
        "    args.downstream_model_checkpoint_fpath,\n",
        "    map_location=torch.device(\"cpu\"),\n",
        ")\n",
        "model.load_state_dict({k.replace(\"model.\", \"\"): v for k, v in fine_tuned_model_ckpt['state_dict'].items()})\n",
        "model.eval()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3amlsjpFd9i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ba8327a-1b4a-478c-c47d-36ed06bd577c"
      },
      "source": [
        "from transformers import PreTrainedTokenizerFast\n",
        "tokenizer = PreTrainedTokenizerFast.from_pretrained(\n",
        "    args.pretrained_model_name,\n",
        "    eos_token=\"</s>\",\n",
        ")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n",
            "The class this function is called from is 'PreTrainedTokenizerFast'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZWVsdmThyV_p"
      },
      "source": [
        "# 인퍼런스 함수 선언\n",
        "인퍼런스 함수를 선언합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fnzR9NMtFiAz"
      },
      "source": [
        "def inference_fn(\n",
        "        prompt,\n",
        "        min_length=10,\n",
        "        max_length=20,\n",
        "        top_p=1.0,\n",
        "        top_k=50,\n",
        "        repetition_penalty=1.0,\n",
        "        no_repeat_ngram_size=0,\n",
        "        temperature=1.0,\n",
        "):\n",
        "    try:\n",
        "        input_ids = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
        "        with torch.no_grad():\n",
        "            generated_ids = model.generate(\n",
        "                input_ids,\n",
        "                do_sample=True,\n",
        "                top_p=float(top_p),\n",
        "                top_k=int(top_k),\n",
        "                min_length=int(min_length),\n",
        "                max_length=int(max_length),\n",
        "                repetition_penalty=float(repetition_penalty),\n",
        "                no_repeat_ngram_size=int(no_repeat_ngram_size),\n",
        "                temperature=float(temperature),\n",
        "           )\n",
        "        generated_sentence = tokenizer.decode([el.item() for el in generated_ids[0]])\n",
        "    except:\n",
        "        generated_sentence = \"\"\"처리 중 오류가 발생했습니다. <br>\n",
        "            변수의 입력 범위를 확인하세요. <br><br> \n",
        "            min_length: 1 이상의 정수 <br>\n",
        "            max_length: 1 이상의 정수 <br>\n",
        "            top-p: 0 이상 1 이하의 실수 <br>\n",
        "            top-k: 1 이상의 정수 <br>\n",
        "            repetition_penalty: 1 이상의 실수 <br>\n",
        "            no_repeat_ngram_size: 1 이상의 정수 <br>\n",
        "            temperature: 0 이상의 실수\n",
        "            \"\"\"\n",
        "    return {\n",
        "        'result': generated_sentence,\n",
        "    }"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 웹서비스 만들기 준비\n",
        "\n",
        "`ngrok`은 코랩 로컬에서 실행 중인 웹서비스를 안전하게 외부에서 접근 가능하도록 해주는 도구입니다. `ngrok`을 실행하려면 [회원가입](https://dashboard.ngrok.com/signup) 후 [로그인](https://dashboard.ngrok.com/login)을 한 뒤 [이곳](https://dashboard.ngrok.com/get-started/your-authtoken)에 접속해 인증 토큰(authtoken)을 확인해야 합니다. 예를 들어 확인된 `authtoken`이 `test111`이라면 다음과 같이 실행합니다.\n",
        "\n",
        "```bash\n",
        "!mkdir /root/.ngrok2 && echo \"authtoken: test111\" > /root/.ngrok2/ngrok.yml\n",
        "```"
      ],
      "metadata": {
        "id": "Xt7Z7G0dB7yY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir /root/.ngrok2 && echo \"authtoken: 2NG8D39Keyp1kkDOVg6Ni91rIg8_4oAFFG6XSpXDV3Hbc1rj5\" > /root/.ngrok2/ngrok.yml"
      ],
      "metadata": {
        "id": "6KshHb4P_0wj"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cat # 파일 탐색\n",
        "!rm #파일 지우기\n",
        "!rm -rf #폴더 지우기"
      ],
      "metadata": {
        "id": "v7KiWaAmQNF0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wPP6ZAaSybge"
      },
      "source": [
        "# 웹서비스 개시\n",
        "아래처럼 실행해 인퍼런스 함수를 웹서비스로 만듭니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_up1ARoHFwLN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9edf66ed-0eda-41ed-fc88-d4df5bfe3c9e"
      },
      "source": [
        "from ratsnlp.nlpbook.generation import get_web_service_app\n",
        "app = get_web_service_app(inference_fn)\n",
        "app.run()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Serving Flask app 'ratsnlp.nlpbook.generation.deploy'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Running on http://adb3-34-125-161-71.ngrok.io\n",
            " * Traffic stats available on http://127.0.0.1:4040\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [20/Mar/2023 04:21:57] \"GET / HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Mar/2023 04:21:58] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Mar/2023 04:24:01] \"POST /api HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Mar/2023 04:24:12] \"POST /api HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Mar/2023 04:24:28] \"POST /api HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Mar/2023 04:24:42] \"POST /api HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Mar/2023 04:24:53] \"POST /api HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Mar/2023 04:25:01] \"POST /api HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Mar/2023 04:25:22] \"POST /api HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Mar/2023 04:25:46] \"POST /api HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Mar/2023 04:25:56] \"POST /api HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Mar/2023 04:26:09] \"POST /api HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Mar/2023 04:26:24] \"POST /api HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Mar/2023 04:26:33] \"POST /api HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Mar/2023 04:26:54] \"POST /api HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Mar/2023 04:28:18] \"POST /api HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Mar/2023 04:28:27] \"POST /api HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Mar/2023 04:29:03] \"POST /api HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Mar/2023 04:29:12] \"POST /api HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Mar/2023 04:29:32] \"POST /api HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Mar/2023 04:29:36] \"POST /api HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Mar/2023 04:29:43] \"POST /api HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Mar/2023 04:29:50] \"POST /api HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Mar/2023 04:30:01] \"POST /api HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Mar/2023 04:30:11] \"POST /api HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Mar/2023 04:30:16] \"POST /api HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Mar/2023 04:30:23] \"POST /api HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Mar/2023 04:32:15] \"POST /api HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Mar/2023 04:32:30] \"POST /api HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Mar/2023 04:32:37] \"POST /api HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Mar/2023 04:32:49] \"POST /api HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Mar/2023 04:34:34] \"POST /api HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Mar/2023 04:34:38] \"POST /api HTTP/1.1\" 200 -\n"
          ]
        }
      ]
    }
  ]
}